{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect the best variables for each role so that we have variables to compare performance between a random player and our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from functools import reduce\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "import sklearn.linear_model as linear\n",
    "import sklearn.tree as tree\n",
    "import sklearn.ensemble as rf\n",
    "import sklearn.svm as svm\n",
    "import sklearn.neural_network as neural\n",
    "\n",
    "import sklearn.feature_selection as feat\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction using isolated player ingame statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_info = pd.read_csv(\"../data/match_info.csv\")\n",
    "laning = pd.read_csv(\"../data/player_laning_stats.csv\")\n",
    "combat = pd.read_csv(\"../data/player_combat_stats.csv\")\n",
    "flair = pd.read_csv(\"../data/player_flair_stats.csv\")\n",
    "objectives = pd.read_csv(\"../data/player_objective_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define a function that handles the cleaning and prediction for us:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(data: pd.DataFrame, lane, model, key_features=[], train=0.9, random_seed=12, feature_selection=0):\n",
    "\n",
    "    # selecting the lanes and dropping non useful columns\n",
    "    data = data.loc[laning[\"lane\"] == lane]\n",
    "    data = data.drop(columns=[\"match_id\",\"account_id\", \"region\", \"champion\", \"lane\"])\n",
    "    try:\n",
    "        data = data.drop(columns=[\"patch\", \"date_created\"])\n",
    "    except:\n",
    "        print(\"sorting columns not found.\")\n",
    "    \n",
    "    # defining our target and variables\n",
    "    target = data[\"won\"]\n",
    "\n",
    "    if len(key_features) > 0:\n",
    "        variables = data[key_features]\n",
    "    else:\n",
    "        variables = data.loc[:, data.columns != \"won\"]\n",
    "\n",
    "    # creating a list of columns so that we can return the top features\n",
    "    columns = variables.columns.to_list()\n",
    "\n",
    "    # standarazing our variables\n",
    "    scale = StandardScaler()\n",
    "    scale.fit(variables)\n",
    "    variables = scale.transform(variables)\n",
    "    del(scale)\n",
    "\n",
    "    # splitting our test and train data\n",
    "    variables_train, variables_test, target_train, target_test = train_test_split(variables, target, train_size=train, random_state=random_seed)\n",
    "\n",
    "    # training the model\n",
    "    model = model()\n",
    "    model.fit(variables_train, target_train);\n",
    "\n",
    "    # implementing feature selection if needed\n",
    "\n",
    "    try:\n",
    "        if feature_selection > 0:\n",
    "\n",
    "            # recursive feature selection\n",
    "            rfe = feat.RFE(model, n_features_to_select=feature_selection);\n",
    "            rfe.fit(variables_train, target_train);\n",
    "    except: \n",
    "        feature_selection = 0\n",
    "    \n",
    "    # returning multiple variables\n",
    "\n",
    "    results = {\n",
    "            \"accuracy\": round(model.score(variables_test, target_test), 3),\n",
    "            #\"balanced_accuracy\":  round(metrics.balanced_accuracy_score(target_test, model.predict(variables_test)), 3),\n",
    "            #\"precision\": round(metrics.precision_score(target_test, model.predict(variables_test)), 3),\n",
    "            #\"avg_precision\": round(metrics.average_precision_score(target_train, model.predict(variables_train)), 3),\n",
    "            \"key_features\": [columns[index] for index, ranking in enumerate(rfe.ranking_) if ranking < 4] if feature_selection > 0 else \"No feature selection\",\n",
    "            }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Laning stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'accuracy': 0.528,\n 'balanced_accuracy': 0.528,\n 'precision': 0.522,\n 'avg_precision': 1.0,\n 'key_features': 'No feature selection'}"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "get_prediction(laning, \"TOP\", tree.DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Combat stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'accuracy': 0.619,\n 'balanced_accuracy': 0.619,\n 'precision': 0.611,\n 'avg_precision': 1.0,\n 'key_features': 'No feature selection'}"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "get_prediction(combat, \"TOP\", tree.DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Objective stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'accuracy': 0.697,\n 'balanced_accuracy': 0.697,\n 'precision': 0.708,\n 'avg_precision': 1.0,\n 'key_features': 'No feature selection'}"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "get_prediction(objectives, \"TOP\", tree.DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Flair stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'accuracy': 0.597,\n 'balanced_accuracy': 0.596,\n 'precision': 0.617,\n 'avg_precision': 0.69,\n 'key_features': 'No feature selection'}"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "get_prediction(flair, \"TOP\", tree.DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the above examples we see that we cannot have an accurate prediction using isolated statistics, we need more data, lets then combine all the player's ingame statistics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with merged player ingame statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Merge the stats and make a prediction for each role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared = [\"match_id\", \"account_id\", \"region\", \"champion\", \"lane\", \"won\"]\n",
    "\n",
    "complete_df = (pd.merge(laning, combat, on=shared, how=\"left\")\n",
    "                .merge(objectives, on=shared, how=\"left\")\n",
    "                .merge(flair, on=shared, how=\"left\")\n",
    "                .fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "TOP: {'accuracy': 0.787, 'balanced_accuracy': 0.787, 'precision': 0.779, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\nJUNGLE: {'accuracy': 0.835, 'balanced_accuracy': 0.836, 'precision': 0.819, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\nMIDDLE: {'accuracy': 0.832, 'balanced_accuracy': 0.833, 'precision': 0.818, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\nBOTTOM: {'accuracy': 0.871, 'balanced_accuracy': 0.871, 'precision': 0.858, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\nSUPPORT: {'accuracy': 0.85, 'balanced_accuracy': 0.85, 'precision': 0.851, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\n"
    }
   ],
   "source": [
    "for x in [\"TOP\", \"JUNGLE\", \"MIDDLE\", \"BOTTOM\", \"SUPPORT\"]:\n",
    "    print(f\"{x}: {get_prediction(complete_df, x, rf.RandomForestClassifier, random_seed=12)}\")\n",
    "    del(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Lets find the best features for TOP lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "key_features = get_prediction(complete_df, \"TOP\", rf.RandomForestClassifier, random_seed=12, feature_selection=9)[\"key_features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['goldpm_10',\n 'dmg_total',\n 'healing_total',\n 'damage_mitigated',\n 'crowd_control',\n 'dmg_taken',\n 'dmg_to_objectives',\n 'dmg_to_turrets',\n 'total_cs',\n 'jungle_invaded',\n 'longest_time_alive']"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "key_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'accuracy': 0.784,\n 'balanced_accuracy': 0.784,\n 'precision': 0.776,\n 'avg_precision': 1.0,\n 'key_features': 'No feature selection'}"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "get_prediction(complete_df, \"TOP\", rf.RandomForestClassifier, random_seed=12, key_features=key_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "11 features selected out of 27\n"
    }
   ],
   "source": [
    "print(f\"{len(key_features)} features selected out of {len(complete_df.drop(columns=['account_id', 'region', 'champion', 'lane']).columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using time and patch variables to see if that increases our accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     match_id region date_created  match_duration  patch winner\n0  4671787510   EUW1   2020-06-21            1557  10.12    Red\n1  4671790912   EUW1   2020-06-21            1716  10.12   Blue\n2  4704868250   EUW1   2020-07-13            1235  10.14    Red\n3  4718171384   EUW1   2020-07-21            2227  10.14    Red\n4  4718095374   EUW1   2020-07-21            1822  10.14   Blue",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>match_id</th>\n      <th>region</th>\n      <th>date_created</th>\n      <th>match_duration</th>\n      <th>patch</th>\n      <th>winner</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4671787510</td>\n      <td>EUW1</td>\n      <td>2020-06-21</td>\n      <td>1557</td>\n      <td>10.12</td>\n      <td>Red</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4671790912</td>\n      <td>EUW1</td>\n      <td>2020-06-21</td>\n      <td>1716</td>\n      <td>10.12</td>\n      <td>Blue</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4704868250</td>\n      <td>EUW1</td>\n      <td>2020-07-13</td>\n      <td>1235</td>\n      <td>10.14</td>\n      <td>Red</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4718171384</td>\n      <td>EUW1</td>\n      <td>2020-07-21</td>\n      <td>2227</td>\n      <td>10.14</td>\n      <td>Red</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4718095374</td>\n      <td>EUW1</td>\n      <td>2020-07-21</td>\n      <td>1822</td>\n      <td>10.14</td>\n      <td>Blue</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "match_info[\"patch\"] = pd.to_numeric(match_info[\"patch\"], errors=\"coerce\")\n",
    "match_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     match_id                                         account_id region  \\\n0  4671787510  7UTpYZvoj06Si113SIlBe-jyteHrh-XRaYzuYfXWentoKm...   EUW1   \n1  4671787510         fG8JDk5zVxKmoAMUqBIE8nbgMqzn8zuJrDJFPslxAg   EUW1   \n2  4671787510    Kc97-m0MqgpSk3DFoY17uq39_Roh9Qvi-xtoEFXPsMhEWPY   EUW1   \n3  4671787510  WmwA8a6PWVm1SkA3JWpID3CDFAbqxjrsU9f345u3_qR12c...   EUW1   \n4  4671787510        4NI6_UJFRWXe6swXbvsN9dQl6ORPjOfU1EA7ybGJjuc   EUW1   \n\n   champion     lane  xppm_10  cspm_10  goldpm_10  dmg_takenpm_10  won  \\\n0        62   JUNGLE    267.3      0.5      261.4           654.3    0   \n1       222   BOTTOM    342.6      6.9      345.3           243.3    0   \n2       412  SUPPORT    274.1      1.1      289.8           311.0    0   \n3       555   MIDDLE    359.4      4.3      341.8           618.7    0   \n4        54      TOP    384.4      5.6      207.2           335.3    0   \n\n   dmg_total  healing_total  units_healed  damage_mitigated  crowd_control  \\\n0       8575           6486             1             14108             72   \n1      15109            365             1              7401             92   \n2       7913            774             5             16784            125   \n3      15786           4251             1             11752            152   \n4      12793            979             1             34204            505   \n\n   dmg_taken  first_blood  first_blood_assist  dmg_to_objectives  \\\n0      22451            0                   0             4718.0   \n1      16096            0                   0             4964.0   \n2      16743            0                   0              342.0   \n3      21388            0                   0             1646.0   \n4      21185            0                   0             1143.0   \n\n   dmg_to_turrets  total_cs  jungle_cs  jungle_invaded  wards_placed  \\\n0           119.0      32.0       57.0             4.0           6.0   \n1          4964.0     190.0       13.0             0.0           6.0   \n2           342.0      23.0        0.0             0.0          31.0   \n3          1264.0      88.0        0.0             0.0           4.0   \n4          1143.0     150.0        0.0             0.0           9.0   \n\n   wards_killed  killing_sprees  longest_time_alive  double_kills  \\\n0           6.0               1                 495             0   \n1           2.0               2                 475             0   \n2           2.0               1                 807             0   \n3           3.0               2                 358             0   \n4           2.0               1                 726             0   \n\n   triple_kills  quadra_kills  penta_kills  patch date_created  \n0             0             0            0  10.12   2020-06-21  \n1             0             0            0  10.12   2020-06-21  \n2             0             0            0  10.12   2020-06-21  \n3             0             0            0  10.12   2020-06-21  \n4             0             0            0  10.12   2020-06-21  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>match_id</th>\n      <th>account_id</th>\n      <th>region</th>\n      <th>champion</th>\n      <th>lane</th>\n      <th>xppm_10</th>\n      <th>cspm_10</th>\n      <th>goldpm_10</th>\n      <th>dmg_takenpm_10</th>\n      <th>won</th>\n      <th>dmg_total</th>\n      <th>healing_total</th>\n      <th>units_healed</th>\n      <th>damage_mitigated</th>\n      <th>crowd_control</th>\n      <th>dmg_taken</th>\n      <th>first_blood</th>\n      <th>first_blood_assist</th>\n      <th>dmg_to_objectives</th>\n      <th>dmg_to_turrets</th>\n      <th>total_cs</th>\n      <th>jungle_cs</th>\n      <th>jungle_invaded</th>\n      <th>wards_placed</th>\n      <th>wards_killed</th>\n      <th>killing_sprees</th>\n      <th>longest_time_alive</th>\n      <th>double_kills</th>\n      <th>triple_kills</th>\n      <th>quadra_kills</th>\n      <th>penta_kills</th>\n      <th>patch</th>\n      <th>date_created</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4671787510</td>\n      <td>7UTpYZvoj06Si113SIlBe-jyteHrh-XRaYzuYfXWentoKm...</td>\n      <td>EUW1</td>\n      <td>62</td>\n      <td>JUNGLE</td>\n      <td>267.3</td>\n      <td>0.5</td>\n      <td>261.4</td>\n      <td>654.3</td>\n      <td>0</td>\n      <td>8575</td>\n      <td>6486</td>\n      <td>1</td>\n      <td>14108</td>\n      <td>72</td>\n      <td>22451</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4718.0</td>\n      <td>119.0</td>\n      <td>32.0</td>\n      <td>57.0</td>\n      <td>4.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>1</td>\n      <td>495</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10.12</td>\n      <td>2020-06-21</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4671787510</td>\n      <td>fG8JDk5zVxKmoAMUqBIE8nbgMqzn8zuJrDJFPslxAg</td>\n      <td>EUW1</td>\n      <td>222</td>\n      <td>BOTTOM</td>\n      <td>342.6</td>\n      <td>6.9</td>\n      <td>345.3</td>\n      <td>243.3</td>\n      <td>0</td>\n      <td>15109</td>\n      <td>365</td>\n      <td>1</td>\n      <td>7401</td>\n      <td>92</td>\n      <td>16096</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4964.0</td>\n      <td>4964.0</td>\n      <td>190.0</td>\n      <td>13.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>2</td>\n      <td>475</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10.12</td>\n      <td>2020-06-21</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4671787510</td>\n      <td>Kc97-m0MqgpSk3DFoY17uq39_Roh9Qvi-xtoEFXPsMhEWPY</td>\n      <td>EUW1</td>\n      <td>412</td>\n      <td>SUPPORT</td>\n      <td>274.1</td>\n      <td>1.1</td>\n      <td>289.8</td>\n      <td>311.0</td>\n      <td>0</td>\n      <td>7913</td>\n      <td>774</td>\n      <td>5</td>\n      <td>16784</td>\n      <td>125</td>\n      <td>16743</td>\n      <td>0</td>\n      <td>0</td>\n      <td>342.0</td>\n      <td>342.0</td>\n      <td>23.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>31.0</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>807</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10.12</td>\n      <td>2020-06-21</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4671787510</td>\n      <td>WmwA8a6PWVm1SkA3JWpID3CDFAbqxjrsU9f345u3_qR12c...</td>\n      <td>EUW1</td>\n      <td>555</td>\n      <td>MIDDLE</td>\n      <td>359.4</td>\n      <td>4.3</td>\n      <td>341.8</td>\n      <td>618.7</td>\n      <td>0</td>\n      <td>15786</td>\n      <td>4251</td>\n      <td>1</td>\n      <td>11752</td>\n      <td>152</td>\n      <td>21388</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1646.0</td>\n      <td>1264.0</td>\n      <td>88.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>2</td>\n      <td>358</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10.12</td>\n      <td>2020-06-21</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4671787510</td>\n      <td>4NI6_UJFRWXe6swXbvsN9dQl6ORPjOfU1EA7ybGJjuc</td>\n      <td>EUW1</td>\n      <td>54</td>\n      <td>TOP</td>\n      <td>384.4</td>\n      <td>5.6</td>\n      <td>207.2</td>\n      <td>335.3</td>\n      <td>0</td>\n      <td>12793</td>\n      <td>979</td>\n      <td>1</td>\n      <td>34204</td>\n      <td>505</td>\n      <td>21185</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1143.0</td>\n      <td>1143.0</td>\n      <td>150.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>9.0</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>726</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10.12</td>\n      <td>2020-06-21</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "sorted_df = complete_df.merge(match_info[[\"match_id\", \"patch\", \"date_created\"]], on=\"match_id\", how=\"left\").dropna()\n",
    "sorted_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. By Patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_patch = sorted_df.loc[sorted_df[\"patch\"] == 10.14]\n",
    "patches = sorted_df.loc[sorted_df[\"patch\"] > 10.12]\n",
    "patches_3 = sorted_df.loc[sorted_df[\"patch\"] >= 10.12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Last patch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "TOP: {'accuracy': 0.769, 'balanced_accuracy': 0.77, 'precision': 0.744, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\nJUNGLE: {'accuracy': 0.839, 'balanced_accuracy': 0.839, 'precision': 0.834, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\nMIDDLE: {'accuracy': 0.821, 'balanced_accuracy': 0.821, 'precision': 0.806, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\nBOTTOM: {'accuracy': 0.852, 'balanced_accuracy': 0.852, 'precision': 0.843, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\nSUPPORT: {'accuracy': 0.849, 'balanced_accuracy': 0.849, 'precision': 0.854, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\n"
    }
   ],
   "source": [
    "for x in [\"TOP\", \"JUNGLE\", \"MIDDLE\", \"BOTTOM\", \"SUPPORT\"]:\n",
    "    print(f\"{x}: {get_prediction(last_patch, x, rf.RandomForestClassifier, random_seed=12, sorted=True)}\")\n",
    "    del(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Last 2 patches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "TOP: {'accuracy': 0.797, 'balanced_accuracy': 0.797, 'precision': 0.782, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\nJUNGLE: {'accuracy': 0.834, 'balanced_accuracy': 0.834, 'precision': 0.821, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\nMIDDLE: {'accuracy': 0.827, 'balanced_accuracy': 0.827, 'precision': 0.824, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\nBOTTOM: {'accuracy': 0.867, 'balanced_accuracy': 0.867, 'precision': 0.86, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\nSUPPORT: {'accuracy': 0.859, 'balanced_accuracy': 0.859, 'precision': 0.865, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\n"
    }
   ],
   "source": [
    "for x in [\"TOP\", \"JUNGLE\", \"MIDDLE\", \"BOTTOM\", \"SUPPORT\"]:\n",
    "    print(f\"{x}: {get_prediction(patches, x, rf.RandomForestClassifier, random_seed=12, sorted=True)}\")\n",
    "    del(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Last 3 patches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "TOP: {'accuracy': 0.785, 'balanced_accuracy': 0.785, 'precision': 0.776, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\nJUNGLE: {'accuracy': 0.839, 'balanced_accuracy': 0.839, 'precision': 0.83, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\nMIDDLE: {'accuracy': 0.831, 'balanced_accuracy': 0.831, 'precision': 0.82, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\nBOTTOM: {'accuracy': 0.867, 'balanced_accuracy': 0.867, 'precision': 0.857, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\nSUPPORT: {'accuracy': 0.858, 'balanced_accuracy': 0.858, 'precision': 0.86, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\n"
    }
   ],
   "source": [
    "for x in [\"TOP\", \"JUNGLE\", \"MIDDLE\", \"BOTTOM\", \"SUPPORT\"]:\n",
    "    print(f\"{x}: {get_prediction(patches_3, x, rf.RandomForestClassifier, random_seed=12, sorted=True)}\")\n",
    "    del(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. By date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(days: int) -> str:\n",
    "    since =  pd.to_datetime(sorted_df[\"date_created\"].max()).date() - timedelta(days=days)\n",
    "    if since.day < 10:\n",
    "        day = f\"0{since.day}\"\n",
    "    else:\n",
    "        day = since.day\n",
    "    if since.month < 10:\n",
    "        month = f\"0{since.month}\"\n",
    "    else:\n",
    "        month = since.month\n",
    "\n",
    "    since = f\"{since.year}-{month}-{day}\"\n",
    "    return since"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_month = sorted_df.loc[sorted_df[\"date_created\"] > get_date(30)]\n",
    "two_weeks = sorted_df.loc[sorted_df[\"date_created\"] > get_date(14)]\n",
    "one_week = sorted_df.loc[sorted_df[\"date_created\"] > get_date(7)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Last month**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "TOP: {'accuracy': 0.786, 'balanced_accuracy': 0.786, 'precision': 0.773, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\nJUNGLE: {'accuracy': 0.837, 'balanced_accuracy': 0.837, 'precision': 0.83, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\nMIDDLE: {'accuracy': 0.834, 'balanced_accuracy': 0.834, 'precision': 0.821, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\nBOTTOM: {'accuracy': 0.869, 'balanced_accuracy': 0.869, 'precision': 0.864, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\nSUPPORT: {'accuracy': 0.865, 'balanced_accuracy': 0.865, 'precision': 0.866, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\n"
    }
   ],
   "source": [
    "for x in [\"TOP\", \"JUNGLE\", \"MIDDLE\", \"BOTTOM\", \"SUPPORT\"]:\n",
    "    print(f\"{x}: {get_prediction(last_month, x, rf.RandomForestClassifier, random_seed=12, sorted=True)}\")\n",
    "    del(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Last two weeks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "TOP: {'accuracy': 0.791, 'balanced_accuracy': 0.791, 'precision': 0.784, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\nJUNGLE: {'accuracy': 0.837, 'balanced_accuracy': 0.837, 'precision': 0.824, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\nMIDDLE: {'accuracy': 0.82, 'balanced_accuracy': 0.82, 'precision': 0.814, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\nBOTTOM: {'accuracy': 0.859, 'balanced_accuracy': 0.859, 'precision': 0.857, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\nSUPPORT: {'accuracy': 0.848, 'balanced_accuracy': 0.848, 'precision': 0.845, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\n"
    }
   ],
   "source": [
    "for x in [\"TOP\", \"JUNGLE\", \"MIDDLE\", \"BOTTOM\", \"SUPPORT\"]:\n",
    "    print(f\"{x}: {get_prediction(two_weeks, x, rf.RandomForestClassifier, random_seed=12, sorted=True)}\")\n",
    "    del(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Last week**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "TOP: {'accuracy': 0.781, 'balanced_accuracy': 0.781, 'precision': 0.79, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\nJUNGLE: {'accuracy': 0.804, 'balanced_accuracy': 0.803, 'precision': 0.807, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\nMIDDLE: {'accuracy': 0.826, 'balanced_accuracy': 0.827, 'precision': 0.798, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\nBOTTOM: {'accuracy': 0.86, 'balanced_accuracy': 0.861, 'precision': 0.851, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\nSUPPORT: {'accuracy': 0.851, 'balanced_accuracy': 0.851, 'precision': 0.853, 'avg_precision': 1.0, 'key_features': 'No feature selection'}\n"
    }
   ],
   "source": [
    "for x in [\"TOP\", \"JUNGLE\", \"MIDDLE\", \"BOTTOM\", \"SUPPORT\"]:\n",
    "    print(f\"{x}: {get_prediction(one_week, x, rf.RandomForestClassifier, random_seed=12, sorted=True)}\")\n",
    "    del(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run multiple algorithms with and without features and store the results so that we can make a better analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_accuracy():\n",
    "\n",
    "    # store results on a dictionary for future analysis\n",
    "    model_accuracy = {\n",
    "        \"model\": [\"rf_classifier\", \"linear_ridge\", \"linear_logistic\", \"linear_svc\", \"linear_stochastic\", \"decision_tree\", \"neural_network\", \"support_vc\"],\n",
    "        \"accuracy_avg\": [],\n",
    "    }\n",
    "\n",
    "    # define the models to use\n",
    "    models = {\n",
    "        \"rf_classifier\": rf.RandomForestClassifier,\n",
    "        \"linear_ridge\": linear.RidgeClassifier,\n",
    "        \"linear_logistic\" : linear.LogisticRegression,\n",
    "        \"linear_svc\": svm.LinearSVC,\n",
    "        \"linear_stochastic\": linear.SGDClassifier,\n",
    "        \"decision_tree\": tree.DecisionTreeClassifier,\n",
    "        \"neural_network\": neural.MLPClassifier,\n",
    "        \"support_vc\": svm.SVC,\n",
    "    }\n",
    "\n",
    "    # define the lanes\n",
    "    lanes = [\"TOP\", \"JUNGLE\", \"MIDDLE\", \"BOTTOM\", \"SUPPORT\"]\n",
    "\n",
    "    # make predictions without features\n",
    "    for i, model in enumerate(models):\n",
    "        results = []\n",
    "        # return mean avg score without features\n",
    "        for lane in lanes:\n",
    "            prediction = get_prediction(last_month, lane, models[model], sorted=True)\n",
    "            results.append(prediction[\"accuracy\"])\n",
    "\n",
    "        # append mean prediction result to model_accuracy\n",
    "        model_accuracy[\"accuracy_avg\"].append(float(format(np.mean(results), \".2f\")))\n",
    "        print(f\"Done at {i}\")\n",
    "\n",
    "    print(\"Done without features\")\n",
    "\n",
    "    return model_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Done at 0\nDone at 1\nDone at 2\nDone at 3\nDone at 4\nDone at 5\nDone at 6\nDone at 7\nDone without features\n"
    }
   ],
   "source": [
    "model_accuracy = get_model_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "               model  accuracy_avg\n0      rf_classifier          0.84\n1       linear_ridge          0.82\n2    linear_logistic          0.83\n3         linear_svc          0.83\n4  linear_stochastic          0.83\n5      decision_tree          0.77\n6     neural_network          0.84\n7         support_vc          0.85",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>accuracy_avg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>rf_classifier</td>\n      <td>0.84</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>linear_ridge</td>\n      <td>0.82</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>linear_logistic</td>\n      <td>0.83</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>linear_svc</td>\n      <td>0.83</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>linear_stochastic</td>\n      <td>0.83</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>decision_tree</td>\n      <td>0.77</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>neural_network</td>\n      <td>0.84</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>support_vc</td>\n      <td>0.85</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "model_accuracy = pd.DataFrame(model_accuracy)\n",
    "model_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the accuracy average I determined that RandomForestClassifier was the best approach, since it is not as high cost as support vector classification or Neural Networks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy.to_pickle(\"../data/model_accuracy.pkl\", protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection and period accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_acc_period():\n",
    "\n",
    "    model_by_period = {\n",
    "        \"period\": [\"complete\", \"last_patch\", \"last_2_patches\", \"last_3_patches\", \"last_month\", \"last_two_weeks\", \"last_week\"],\n",
    "        \"TOP\": [],\n",
    "        \"JUNGLE\": [],\n",
    "        \"MIDDLE\": [],\n",
    "        \"BOTTOM\": [],\n",
    "        \"SUPPORT\": [],\n",
    "    } \n",
    "\n",
    "    lane_features = {\n",
    "        \"TOP\": [],\n",
    "        \"JUNGLE\": [],\n",
    "        \"MIDDLE\": [],\n",
    "        \"BOTTOM\": [],\n",
    "        \"SUPPORT\": [],\n",
    "    }\n",
    "\n",
    "    # define the iterations\n",
    "    periods = {\n",
    "        \"complete\": complete_df,\n",
    "        \"last_patch\": last_patch,\n",
    "        \"last_2_patches\": patches,\n",
    "        \"last_3_patches\": patches_3,\n",
    "        \"last_month\": last_month, \n",
    "        \"last_two_weeks\": two_weeks, \n",
    "        \"last_week\": one_week\n",
    "        }\n",
    "\n",
    "    # define the lanes\n",
    "    lanes = [\"TOP\", \"JUNGLE\", \"MIDDLE\", \"BOTTOM\", \"SUPPORT\"]\n",
    "\n",
    "    # without features\n",
    "    for period in periods:\n",
    "        for lane in lanes:\n",
    "            prediction = get_prediction(periods[period], lane, rf.RandomForestClassifier)\n",
    "            model_by_period[lane].append(prediction[\"accuracy\"])\n",
    "\n",
    "    for lane in lane_features:\n",
    "        prediction = get_prediction(last_month, lane, rf.RandomForestClassifier, feature_selection=7)\n",
    "        lane_features[lane].append(prediction[\"key_features\"])\n",
    "\n",
    "    return [model_by_period, lane_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "sorting columns not found.\nsorting columns not found.\nsorting columns not found.\nsorting columns not found.\nsorting columns not found.\n"
    }
   ],
   "source": [
    "results = get_model_acc_period()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'period': ['complete',\n  'last_patch',\n  'last_2_patches',\n  'last_3_patches',\n  'last_month',\n  'last_two_weeks',\n  'last_week'],\n 'TOP': [0.785, 0.773, 0.796, 0.785, 0.786, 0.786, 0.793],\n 'JUNGLE': [0.834, 0.837, 0.837, 0.838, 0.838, 0.836, 0.816],\n 'MIDDLE': [0.833, 0.824, 0.827, 0.832, 0.833, 0.827, 0.823],\n 'BOTTOM': [0.871, 0.849, 0.867, 0.866, 0.868, 0.856, 0.86],\n 'SUPPORT': [0.85, 0.85, 0.86, 0.86, 0.863, 0.849, 0.856]}"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results[0]).to_pickle(\"../data/model_by_period.pkl\", protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results[1]).to_pickle(\"../data/lane_features.pkl\", protocol=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('ironhack': conda)",
   "language": "python",
   "name": "python38364bitironhackcondae22397c42f6b4fd29a9381c81ac70f68"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}